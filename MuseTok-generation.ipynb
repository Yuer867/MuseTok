{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6b5d71",
   "metadata": {},
   "source": [
    "## Symbolic Music Generation with MuseTok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e13213",
   "metadata": {},
   "source": [
    "### Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9db2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4dc6ba",
   "metadata": {},
   "source": [
    "### Download checkpoints and unzip\n",
    "\n",
    "1. download checkpoints from link: https://drive.google.com/file/d/1HK534lEVdHYl3HMRkKvz8CWYliXRmOq_/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. unzip the file\n",
    "!unzip ckpt.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ddcd5",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65a94e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jingyue/miniconda3/envs/mmp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] successfully load tokenizer\n",
      "[info] successfully load generator\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained tokenizer and generator\n",
    "import torch\n",
    "import numpy as np\n",
    "from model.musetok import TransformerResidualVQ, GPT2TokenGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "device = 'cuda'\n",
    "num_quantizers = 16\n",
    "codebook_size = 2048\n",
    "\n",
    "tokenizer_path = 'ckpt/best_tokenizer/model.pt'\n",
    "tokenizer = TransformerResidualVQ(\n",
    "    enc_n_layer=12, enc_n_head=8, enc_d_model=512, enc_d_ff=2048,\n",
    "    dec_n_layer=12, dec_n_head=8, dec_d_model=512, dec_d_ff=2048,\n",
    "    d_vae_latent=128, d_embed=512, n_token=168,\n",
    "    num_quantizers=16, codebook_size=2048,\n",
    "    rotation_trick=True, rvq_type='SimVQ'\n",
    ").to(device)\n",
    "tokenizer.eval()\n",
    "tokenizer.load_state_dict(torch.load(tokenizer_path, map_location='cpu'))\n",
    "print('[info] successfully load tokenizer')\n",
    "\n",
    "generator_path = 'ckpt/best_generator/model.pt'\n",
    "generator = GPT2TokenGenerator(\n",
    "    dec_n_layer=12, dec_n_head=16, dec_d_model=1024, dec_d_ff=2048,\n",
    "    d_embed=512, n_token=32771, n_bar=16\n",
    ").to(device)\n",
    "generator.eval()\n",
    "generator.load_state_dict(torch.load(generator_path, map_location='cpu'))\n",
    "print('[info] successfully load generator')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd648c1",
   "metadata": {},
   "source": [
    "### Music Continuation\n",
    "Generate music pieces by continuing the prompts (e.g. 4 bars) from the provided MIDI file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a9e64fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Represent MIDI file test/Classic_358.mid ...\n",
      "[info] time signature = 4/4\n",
      "[info] got 16 bars, 999 events\n",
      "[info] Shape of MuseTok codes: (16, 16)\n",
      "[info] Shape of corresponding embeddings: (16, 128)\n"
     ]
    }
   ],
   "source": [
    "from data_processing.midi2events import midi_analyzer, midi2corpus_strict, corpus2events\n",
    "from encoding import MuseTokEncoder\n",
    "from test_generation import generate_tokens, decode_tokens, word2event, TempoEvent\n",
    "from remi2midi import remi2midi\n",
    "from utils import numpy_to_tensor\n",
    "\n",
    "file = 'test/Classic_358.mid'\n",
    "primer_n_bar = 4\n",
    "\n",
    "# represent MIDI file into music events\n",
    "midi_obj, bar_resol = midi_analyzer(file)\n",
    "full_data = midi2corpus_strict(midi_obj, bar_resol, remove_overlap=True)\n",
    "pos, events = corpus2events(full_data, bar_resol, time_first=False, has_velocity=False, repeat_beat=True, remove_short=False)\n",
    "print('[info] got {} bars, {} events'.format(len(pos), len(events)))\n",
    "\n",
    "# encode music events\n",
    "encoder = MuseTokEncoder(tokenizer, device=device)\n",
    "music_data = encoder.get_segments(events, pos)\n",
    "indices, latents = encoder.encoding(music_data, return_latents=True)\n",
    "print('[info] Shape of MuseTok codes: {}'.format(indices.shape))\n",
    "print('[info] Shape of corresponding embeddings: {}'.format(latents.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "201704b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] generated 5 bars\n",
      "[info] generated 6 bars\n",
      "[info] generated 7 bars\n",
      "[info] generated 8 bars\n",
      "[info] generated 9 bars\n",
      "[info] generated 10 bars\n",
      "[info] generated 11 bars\n",
      "[info] generated 12 bars\n",
      "[info] generated 13 bars\n",
      "[info] generated 14 bars\n",
      "[info] generated 15 bars\n",
      "[info] generated 16 bars\n",
      "-- time elapsed: 3.18 secs\n"
     ]
    }
   ],
   "source": [
    "# generate MuseTok codes by continuation\n",
    "indices = (indices + np.arange(num_quantizers) * codebook_size).reshape(-1).tolist()\n",
    "bos_token = len(range(num_quantizers * codebook_size))\n",
    "prompt = [bos_token] + indices[:primer_n_bar * num_quantizers]\n",
    "\n",
    "gen_tokens, t_sec = generate_tokens(\n",
    "    generator, primer=prompt, primer_n_bar=primer_n_bar,\n",
    "    max_bars=16, num_tokens=num_quantizers, codebook_size=codebook_size,\n",
    "    temp=1.1, top_p=0.9, top_k=30, eos=bos_token + 1\n",
    ")\n",
    "\n",
    "# transfer codes to corresponding embeddings\n",
    "num_bars = len(gen_tokens) // num_quantizers\n",
    "gen_tokens = np.array(gen_tokens) - np.tile(np.arange(num_quantizers), num_bars) * codebook_size\n",
    "gen_indices = numpy_to_tensor(gen_tokens, device=device).view(-1, num_quantizers).long()\n",
    "gen_latents = tokenizer.residual_sim_vq.get_output_from_indices(gen_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39cb0f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] generated 1 bars, #events = 50\n",
      "[info] generated 2 bars, #events = 112\n",
      "[info] generated 3 bars, #events = 168\n",
      "[info] generated 4 bars, #events = 218\n",
      "[info] generated 5 bars, #events = 274\n",
      "[info] generated 6 bars, #events = 336\n",
      "[info] generated 7 bars, #events = 404\n",
      "[info] generated 8 bars, #events = 463\n",
      "[info] generated 9 bars, #events = 546\n",
      "[info] generated 10 bars, #events = 608\n",
      "[info] generated 11 bars, #events = 688\n",
      "[info] generated 12 bars, #events = 771\n",
      "[info] generated 13 bars, #events = 836\n",
      "[info] generated 14 bars, #events = 901\n",
      "[info] generated 15 bars, #events = 972\n",
      "[info] generated 16 bars, #events = 1025\n",
      "-- generated events: 1026\n",
      "-- time elapsed: 34.78 secs\n"
     ]
    }
   ],
   "source": [
    "# decode codes back to music events\n",
    "song, t_sec = decode_tokens(\n",
    "    tokenizer, gen_latents,\n",
    "    encoder.event2idx, encoder.idx2event, device,\n",
    "    max_events=12800\n",
    ")\n",
    "song = word2event(song, encoder.idx2event)\n",
    "\n",
    "out_file = 'test/continuation'\n",
    "midi_obj = remi2midi(\n",
    "    song, \n",
    "    out_file + '.mid', \n",
    "    enforce_tempo=True, \n",
    "    enforce_tempo_val=[TempoEvent(110, 0, 0, 4, 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85226c19",
   "metadata": {},
   "source": [
    "## Music Generation from Scratch\n",
    "Generate music pieces without prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04dc97cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] generated 1 bars\n",
      "[info] generated 2 bars\n",
      "[info] generated 3 bars\n",
      "[info] generated 4 bars\n",
      "[info] generated 5 bars\n",
      "[info] generated 6 bars\n",
      "[info] generated 7 bars\n",
      "[info] generated 8 bars\n",
      "[info] generated 9 bars\n",
      "[info] generated 10 bars\n",
      "[info] generated 11 bars\n",
      "[info] generated 12 bars\n",
      "-- time elapsed: 3.15 secs\n"
     ]
    }
   ],
   "source": [
    "# generate MuseTok codes from scratch\n",
    "gen_tokens, t_sec = generate_tokens(\n",
    "    generator, primer=[bos_token], primer_n_bar=primer_n_bar,\n",
    "    max_bars=16, num_tokens=num_quantizers, codebook_size=codebook_size,\n",
    "    temp=1.1, top_p=0.9, top_k=30, eos=bos_token + 1\n",
    ")\n",
    "\n",
    "# transfer codes to corresponding embeddings\n",
    "num_bars = len(gen_tokens) // num_quantizers\n",
    "gen_tokens = np.array(gen_tokens) - np.tile(np.arange(num_quantizers), num_bars) * codebook_size\n",
    "gen_indices = numpy_to_tensor(gen_tokens, device=device).view(-1, num_quantizers).long()\n",
    "gen_latents = tokenizer.residual_sim_vq.get_output_from_indices(gen_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29f9a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] generated 1 bars, #events = 8\n",
      "[info] generated 2 bars, #events = 25\n",
      "[info] generated 3 bars, #events = 42\n",
      "[info] generated 4 bars, #events = 56\n",
      "[info] generated 5 bars, #events = 70\n",
      "[info] generated 6 bars, #events = 87\n",
      "[info] generated 7 bars, #events = 107\n",
      "[info] generated 8 bars, #events = 127\n",
      "[info] generated 9 bars, #events = 135\n",
      "[info] generated 10 bars, #events = 152\n",
      "[info] generated 11 bars, #events = 169\n",
      "[info] generated 12 bars, #events = 186\n",
      "-- generated events: 187\n",
      "-- time elapsed: 2.12 secs\n"
     ]
    }
   ],
   "source": [
    "# decode codes back to music events\n",
    "song, t_sec = decode_tokens(\n",
    "    tokenizer, gen_latents,\n",
    "    encoder.event2idx, encoder.idx2event, device,\n",
    "    max_events=12800\n",
    ")\n",
    "song = word2event(song, encoder.idx2event)\n",
    "\n",
    "out_file = 'test/generation'\n",
    "midi_obj = remi2midi(\n",
    "    song, \n",
    "    out_file + '.mid', \n",
    "    enforce_tempo=True, \n",
    "    enforce_tempo_val=[TempoEvent(110, 0, 0, 4, 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f83f62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
