data:
    data_dir:         ../data_events/data_pdmx_rvq_piano_density_s512
    train_split:      ../data_events/data_pdmx_rvq_piano_density_s512/splits_piano/train_split.pkl
    val_split:        ../data_events/data_pdmx_rvq_piano_density_s512/splits_piano/val_split.pkl
    test_split:       ../data_events/data_pdmx_rvq_piano_density_s512/splits_piano/val_split.pkl
    time_path:        ../data_events/data_pdmx_rvq_piano_density_s512/timeSig2pieces_piano.pkl
    density_path:     ../data_events/data_pdmx_rvq_piano_density_s512/density2pieces_piano.pkl
    max_bars:         16
    num_quantizers:   8     # vae
    codebook_size:    512  # vae
    batch_size:       128
    balanced_time:    False
    balanced_density: True
    first_token_only: False
    first_token_first: False

model:
    dec_n_layer:      12
    dec_n_head:       8
    dec_d_model:      512
    dec_d_ff:         2048
    d_embed:          128
    use_bar_emb:      True
    pretrained_params_path:  ckpt/gen_12L_8H_512D_128E-16_bars_1280-pdmx-density-s512/params/step_55000-RC_2.329-model.pt
    pretrained_optim_path:   ckpt/gen_12L_8H_512D_128E-16_bars_1280-pdmx-density-s512/optim/step_55000-RC_2.329-optim.pt

training:
    device:           cuda:0
    ckpt_dir:         ./ckpt/enc_dec_12L-16_bars-seqlen_1280-rvq-pdmx-n4-s1024
    trained_steps:    55000
    max_epochs:       1000
    max_lr:           1.0e-4
    min_lr:           5.0e-6
    lr_warmup_steps:  100  # 200
    lr_decay_steps:   15000  # 150000
    free_bit_lambda:  0.25
    ckpt_interval:    5000
    log_interval:     10
    val_interval:     50
    val_rounds:       1

data_music:
    data_dir:         ../data_events/data_pdmx_remi+_balanced_simplified
    test_split:       ../data_events/data_pdmx_remi+_balanced_simplified/splits_piano/val_split.pkl
    vocab_path:       ../data_events/data_pdmx_remi+_balanced_simplified/dictionary.pkl
    max_bars:         16
    enc_seqlen:       128
    dec_seqlen:       1280

tokenizer:
    enc_n_layer:      12
    enc_n_head:       8
    enc_d_model:      512
    enc_d_ff:         2048
    dec_n_layer:      12
    dec_n_head:       8
    dec_d_model:      512
    dec_d_ff:         2048
    d_embed:          512
    d_latent:         128   # vae
    num_quantizers:   8     # vae
    codebook_size:    1024  # vae
    pretrained_tokenizer_path:  ckpt/enc_dec_12L-16_bars-seqlen_1280-rvq-pdmx-n8-s1024-d128-beta1-density/params/step_16000-RC_0.122-CM_0.036-model.pt
    rotation_trick:   True
    rvq_type:         SimVQ # FSQ

decoder:
    dec_n_layer:      12
    dec_n_head:       16
    dec_d_model:      1024
    dec_d_ff:         2048
    d_embed:          1024
    d_latent:         128   # vae
    pretrained_decoder_path:  ckpt/dec_12L_16H_1024D-16_bars-seqlen_1280-pdmx-n8-s1024-d128-density/params/step_17000-RC_0.081-model.pt

generate:
    temperature:                1.1
    nucleus_p:                  0.8
    use_latent_sampling:        False
    latent_sampling_var:        0.0
    max_bars:                   16       # could be set to match the longest input piece during generation (inference)
    num_quantizers:             8        # vae
    codebook_size:              1024  # vae
    dec_seqlen:                 1280     # could be set to match the longest input piece during generation (inference)
    max_input_dec_seqlen:       1024     # should be set to equal to or less than `dec_seqlen` used during training